defaults:
  - _self_
  - experiment: weight_averaging

base_model: "meta-llama/Llama-3.1-8B-Instruct"
output_dir: null
model_limit: 1000
model_dir: null
eval_every_n_merges: 1
evaluate_current: false
min_current_accuracy: 20.0
greedy: false
greedy_eval_samples: 100
eval_runs: 5
batch_size: 32
datasets:
  - mmlu
  - mmlu_pro
  - math500
  - gpqa

hydra:
  run:
    dir: "outputs/hydra"

merge:
  method: weight_averaging_running

  ema:
    beta: 0.5

  task_arithmetic:
    scaling_factor: 1.0

  ties:
    scaling_factor: 1.0
    prune_percentile: 0.2
